# 数据清洗

本工程是对于 `step1-crawl` 所爬取数据的数据清洗。

## 清洗要点

* 使用经过爬虫后得到的数据集
* 清理要点
    * `【注释】【赏析】【译文】`字眼（以及其之后的数据）去掉，不需要
    * 去掉诗歌正文中的`【...】（...）[...]`
    * 诗歌正文中的`{x[d]y}`数据，转换为`x`（去掉了`{`和`[d]y}`）
    * 诗歌正文字符串转换为字符数组，按照换行切分（`\r\n \n\r \r \n`）
    * 统计各个朝代的诗歌数量，以及诗歌总量

## 工程所需

* python 3.6

## 输入

输入为 `input/dist/`，直接在 `input/` 下解压爬虫工程中的 `dist.zip` 即可。

> **务必严格遵守输入路径！否则脚本无法运行！**

## 输出

为根目录下的 `output/` 目录下的内容。

> **运行脚本前，请删除此目录**

## 运行

1. 下载工程
2. 在 `src/` 下启动命令行
3. 执行 `python clean.py` 即可

---

## 实用 Python 方法

* os.listdir() 返回目录下所有的文件夹和文件
    * 可以利用此信息进行深度优先的目录遍历
* str.split() 可按照字符串进行拆分
    * split可以使用字符串为参数
* re.split() 可做复杂切分
    * 通过置入正则表达式，可以进行更为复杂的字符串切分操作